<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Hadoop Overview | myBlog</title><meta name="keywords" content="Big Data Systems,Cloud Computing"><meta name="author" content="Donald Lam,manholam8@gmail.com"><meta name="copyright" content="Donald Lam"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="HadoopHadoop is a reliable shared storage and analysis system. The storage is provided by Hadoop Distributed File System (HDFS) and analysis by MapReduce. MapReduce MapReduce is a programming model th">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop Overview">
<meta property="og:url" content="https://github.com/DonaldLamNL/myBlog/2023/09/15/CUHK/CSCI4180/2023-9-15-CSCI4180-Hadoop/index.html">
<meta property="og:site_name" content="myBlog">
<meta property="og:description" content="HadoopHadoop is a reliable shared storage and analysis system. The storage is provided by Hadoop Distributed File System (HDFS) and analysis by MapReduce. MapReduce MapReduce is a programming model th">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://p.ipic.vip/hwdr0p.jpg">
<meta property="article:published_time" content="2023-09-14T16:00:00.000Z">
<meta property="article:modified_time" content="2023-09-14T16:00:00.000Z">
<meta property="article:author" content="Donald Lam">
<meta property="article:tag" content="Big Data Systems">
<meta property="article:tag" content="Cloud Computing">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://p.ipic.vip/hwdr0p.jpg"><link rel="shortcut icon" href="/myBlog/img/favicon.png"><link rel="canonical" href="https://github.com/DonaldLamNL/myBlog/2023/09/15/CUHK/CSCI4180/2023-9-15-CSCI4180-Hadoop/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/myBlog/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/myBlog/',
  algolia: undefined,
  localSearch: {"path":"/myBlog/search.xml","preload":true,"languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Hadoop Overview',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-09-15 00:00:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://p.ipic.vip/5dc8z2.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/myBlog/archives/"><div class="headline">Articles</div><div class="length-num">66</div></a><a href="/myBlog/tags/"><div class="headline">Tags</div><div class="length-num">14</div></a><a href="/myBlog/categories/"><div class="headline">Categories</div><div class="length-num">14</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/myBlog/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://p.ipic.vip/hwdr0p.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/myBlog/">myBlog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/myBlog/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Hadoop Overview</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-09-14T16:00:00.000Z" title="Created 2023-09-15 00:00:00">2023-09-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-09-14T16:00:00.000Z" title="Updated 2023-09-15 00:00:00">2023-09-15</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/myBlog/categories/CSCI4180/">CSCI4180</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Hadoop Overview"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><p>Hadoop is a reliable shared storage and analysis system. The storage is provided by <font color="3A75EA">Hadoop Distributed File System (HDFS)</font> and analysis by <font color="3A75EA">MapReduce</font>.</p>
<h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><ul>
<li><p>MapReduce is a programming model that gives:</p>
<ol>
<li>Automatic parallelization and distribution</li>
<li>Fault-tolerance</li>
<li>I/O scheduling</li>
<li>Status and monitoring</li>
</ol>
</li>
<li><p><strong>Properties</strong></p>
<ol>
<li><font color="F54747">same key always go to the same reduce function</font></li>
<li><font color="F54747">all value associated to the same key will appear once and only once</font></li>
<li><font color="F54747">the reduce function cannot start until all map functions are finished</font></li>
<li><font color="F54747">the key would be sorted for each reducer</font></li>
<li>the code is not optimized</li>
</ol>
</li>
</ul>
<h3 id="Programming-Model"><a href="#Programming-Model" class="headerlink" title="Programming Model"></a>Programming Model</h3><ul>
<li>Input and output: each a set of key/value pairs</li>
<li><p>Two functions implemented by users</p>
<ol>
<li><p><font color="F54747"><strong>Mapper</strong></font>: <code>(k1, v1) → list(k2,v2)</code></p>
<ul>
<li>Takes an input key/value pair</li>
<li>Produces a set of intermediate key/value pairs</li>
</ul>
</li>
<li><p><font color="F54747"><strong>Reducer</strong></font>: <code>(k2, list(v2)) → list(k3,v3)</code></p>
<ul>
<li>Takes a set of values for an intermediate key</li>
<li>Produces a set of output values</li>
</ul>
</li>
</ol>
</li>
<li><p><font color="00A300">WordCount Example</font>:</p>
<ol>
<li><p>The mapper takes an input key-value pair, tokenizes the document, and emits an intermediate key-value pair for each word. (<code>word → key</code>, <code>1 → value</code>)</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">MAP(String key, String value):</span><br><span class="line">    <span class="comment">// key: document name, value: document content</span></span><br><span class="line">    <span class="keyword">for</span> each word w in value:</span><br><span class="line">        Emit(w, <span class="string">&quot;1&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>The reducer sums up all counts associated each word, and emits final key-value pairs with the word as the key</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">REDUCER(String key, Iterator values)</span><br><span class="line">    <span class="comment">// key: a word, values: a list of counts</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> each v in values:</span><br><span class="line">        result += ParseInt(v)</span><br><span class="line">    Emit(key, AsString(result))</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>Notice:</strong> All values of the same word will go to the same reducer at the same time.</li>
</ul>
</li>
</ol>
</li>
</ul>
<h3 id="Data-Flow"><a href="#Data-Flow" class="headerlink" title="Data Flow"></a>Data Flow</h3><p>A MapReduce job is a unit of work that the client wants to be performed. Hadoop runs the job by dividing it into tasks (map tasks and reduce tasks).</p>
<p><img src="https://p.ipic.vip/y8dksh.png" width="500px" /></p>
<ul>
<li><p><strong>Nodes:</strong> control the job execution process</p>
<ol>
<li><strong><font color="3A75EA">Master</font></strong>: coordinates all jobs</li>
<li><strong><font color="3A75EA">Workers/Slaves</font></strong>: runs tasks and sends reports to master</li>
</ol>
</li>
<li><p><strong>Split:</strong> Hadoop divides the input to a MapReduce job into fixed-size pieces called splits</p>
<ul>
<li>Hadoop creates one map task for each split and map function runs each record in the split.</li>
</ul>
</li>
<li><p><strong>Split size:</strong></p>
<ul>
<li>too large: lacks parallelization</li>
<li>too small: increases management overhead</li>
<li>A good split size = HDFS block (default = 128MB)</li>
</ul>
</li>
<li><p><font color="F54747"><strong>Data locality optimization</strong></font></p>
<ul>
<li>Hadoop tries to run the map task on a node where the input data resides in <strong>HDFS</strong>.</li>
<li>Map tasks write their output to the local disk (<strong>not in HDFS</strong>).</li>
<li>Reduce tasks don’t have the advantage of data locality — the input to a single reduce task is normally the output from all mappers.</li>
</ul>
</li>
<li><p><font color="F54747"><strong>Dealing with Failures</strong></font></p>
<ul>
<li><strong>Map worker failure</strong><ul>
<li>Map tasks <font color="F54747">completed or in-progress</font> at worker are reset to idle</li>
<li>Reduce workers are notified when task is rescheduled on another worker</li>
</ul>
</li>
<li><strong>Reduce worker failure</strong><ul>
<li><font color="F54747">Only in-progress</font> tasks are reset to idle</li>
<li>Reduce task is restarted </li>
</ul>
</li>
<li><strong>Master failure</strong><ul>
<li>MapReduce task is aborted and client is notified</li>
</ul>
</li>
</ul>
</li>
<li><p><font color="F54747"><strong>Fault Tolerance</strong></font></p>
<ul>
<li>If the node running the map task fails before the map output has been consumed by the reduce task, then Hadoop will automatically <font color="F54747">re-run</font> the map task on another node to re-create the map output.</li>
<li>The output of reduce is normally sorted in HDFS for reliability where the first replica is stored on the local node and other replicas are stored on off-rack nodes.<br><img src="https://p.ipic.vip/hnuesu.png" width="500px" /></li>
</ul>
</li>
</ul>
<h3 id="Partition-and-Combiner"><a href="#Partition-and-Combiner" class="headerlink" title="Partition and Combiner"></a>Partition and Combiner</h3><ol>
<li><p><font color="F54747"><strong>Partition</strong></font></p>
<ul>
<li>Map outputs are partitioned to multiple reduce tasks</li>
<li>Simple hash key <code>H(k) mod #R</code> (can be user-defined)</li>
</ul>
</li>
<li><p><font color="F54747"><strong>Combiner</strong></font></p>
<ul>
<li>Map outputs are reduced before being sent to reducers</li>
<li>Used as an <font color="3A75EA">optimization</font> to reduce network traffic</li>
<li>MapReduce can only run the combine function if it has time, we have no idea when do the combine function be executed, it is controled by the MapReduce Schedule</li>
<li><p>Since the reducer would either take the input from mappers or combiners, it is necessary to ensure the output format of mapper and combiner are same as the input format of reducers</p>
<p><img src="https://p.ipic.vip/kc4i3t.png" width="500px" /></p>
</li>
</ul>
</li>
</ol>
<h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><p>Hadoop Distributed Filesystem (HDFS) is a filesystem designed for storing very large files with streaming data access patterns, running on clusters of commodity hardware.</p>
<ul>
<li><p><strong>Assumptions:</strong></p>
<ol>
<li><font color="F54747">Very large files</font></li>
<li><font color="F54747">Streaming data access</font>: write-one, read-many-times pattern (WORM)</li>
<li><font color="F54747">Commodity hardware</font>: hardware failure is a norm rather than exception</li>
</ol>
</li>
<li><p><strong>More Goals:</strong></p>
<ol>
<li><font color="3A75EA">Simple coherency model</font>: data won’t be changed (synchronization overhead)</li>
<li><font color="3A75EA">Moving computation is cheaper than moving data</font></li>
<li><font color="3A75EA">Portability across heterogeneous hardware and software platforms</font>
</li>
</ol>
</li>
<li><p><strong>Not Suitable:</strong></p>
<ol>
<li>requires low-latency data access</li>
<li>lot of small files</li>
<li>multiple writers, arbitrary file modifications</li>
</ol>
</li>
</ul>
<h3 id="HDFS-Architectural"><a href="#HDFS-Architectural" class="headerlink" title="HDFS Architectural"></a>HDFS Architectural</h3><p><img src="https://p.ipic.vip/723147.png" width="500px" /></p>
<ul>
<li><p><strong>Architectural</strong></p>
<ul>
<li><font color="F54747">A namenode</font>: a master server that manages the file system namespace and regulates access to files by clients.</li>
<li><font color="F54747">Multiple datanode</font>: each manages storage attached to the nodes, and serves read/write data requests from clients.</li>
</ul>
</li>
<li><p><strong>Data Blocks</strong><br>HDFS arranges data in blocks of very large size (128MB by default), which designed for very large files</p>
<ul>
<li>too small: increase management overhead + expensive in disk seeks</li>
<li>too large: loss parallelism that cannot access the block parallelly by datanodes</li>
</ul>
</li>
<li><p><strong>Namespace</strong><br>HDFS supports a traditional hierarchical file organization, one can create and remove files, move a file from one directory to another, or rename a file.</p>
</li>
<li><p><strong><font color="F54747">Data Replication</font></strong><br>Blocks of a file are replicated (create identical copies) for fault tolerance. The block size and replication factor (number of copies) can be defined in the configuration.<br>The namenode makes the decision of regarding replications of blocks. It periodically receives a <font color="3A75EA">Heartbeat</font> (keep-alive message) and <font color="3A75EA">Blockreport</font> (a list of all blocks) from each of the datanodes.</p>
<ul>
<li>Default replication factor is 3 (2 in single machine)</li>
<li><font color="F54747">Rack-aware placement</font>: balance the reliability and write performance<ol>
<li>One replica in one node in the locak rack</li>
<li>One replica in another node in the local rack (if node fault, it can search from other server in same rack)</li>
<li>One replica in a different node in a different rack</li>
</ol>
</li>
</ul>
</li>
<li><p><strong>Robustness</strong></p>
<ul>
<li><p>Data disk failures</p>
<ul>
<li>if namenode receives no heartbeats which means datanode fails, re-replicate data to new datanodes</li>
</ul>
</li>
<li><p>Cluster rebalancing</p>
<ul>
<li>HDFS can dynamically generate new replicas and rebalance other data in the cluster</li>
</ul>
</li>
<li><p>Data integrity</p>
<ul>
<li>Checksum is attached to each block</li>
</ul>
</li>
<li><p>Namenode failure</p>
<ul>
<li>Currently it’s a single point of failure in HDFS</li>
<li>Needs manual intervention</li>
</ul>
</li>
<li><p>Snapshots</p>
<ul>
<li>Currently not supported</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Read"><a href="#Read" class="headerlink" title="Read"></a>Read</h3><ul>
<li><p><strong><font color="F54747">HDFS Read Steps</font></strong><br>  <img src="https://p.ipic.vip/vfb05m.png" width="500px" /></p>
<ol>
<li>HDFS client opens the file through the file system object.</li>
<li>The file system object calls the namenode, using RPC, to determine the locations of the blocks for the first few blocks in the file. The file system object returns an input stream.</li>
<li>The client then calls the read function to retrieve data blocks through the input stream.</li>
<li>Data is streamed from the datanode back to client, which calls the read function repeatedly on the input stream.</li>
<li>When the end of the block is reached, the input stream will close the connection to the datanode, then find the best datanode for the next block</li>
<li>When the client has finished reading, it closes the input stream.</li>
</ol>
</li>
<li><p><strong>Notices</strong></p>
<ol>
<li>The client contacts datanodes directly to retrieve data and is guided by the namenode to the best datanode for each block. <font color="3A75EA">Namenode doesn’t serve data</font>.</li>
<li><p>If the input stream encounters an error while communicating with a datanode, then it will try the next “closest” one for that block. The distance is defined in considering the network as a tree:</p>
<ol>
<li>Distance 0: processes on the same node</li>
<li>Distance 2: processes on the different nodes but on the same rack</li>
<li>Distance 4: processes on the nodes on different racks but in the same data center</li>
<li><p>Distance 6: processes on the same nodes in different data centers</p>
<p><img src="https://p.ipic.vip/haydda.png" width="500px" /></p>
</li>
</ol>
</li>
</ol>
</li>
</ul>
<h3 id="Write"><a href="#Write" class="headerlink" title="Write"></a>Write</h3><ul>
<li><p><strong><font color="F54747">HDFS Write Steps</font></strong><br>  <img src="https://p.ipic.vip/6epo93.png" width="500px" /></p>
<ol>
<li>HDFS client creates the file on the file system object.</li>
<li>The file system object makes an RPC call to the namenode to create a new file in the filesystem’s namespace. An output stream is created.</li>
<li>As the client writes data, the output stream splits it into packets, which it writes to an internal queue called the data queue.</li>
<li>The output stream streams the packets to the first datanode in the pipeline, which stores the packet and forwards it to the second datanode in the pipeline, followed by the third (and last) datanode in the pipeline.</li>
<li>The output stream maintains an internal queue of packets that are waiting to be acknowledged by datanodes called the ack queue. A packet is removed from the ack queue only when it has been acknowledged by all the datanodes in the pipeline.</li>
<li>When the client has finished writing data, it closes the output stream.</li>
<li>The client contacts the namenode to signal that the file is complete.</li>
</ol>
</li>
</ul>
<ul>
<li><p><strong>Implementation</strong><br>  <img src="https://p.ipic.vip/coys7o.png" width="500px" /></p>
<ol>
<li><p><strong>Pipeline</strong>:<br> it recieves one full copy of data block, sends it forward (needless to wait for recieving all data)</p>
<ul>
<li>Bottleneck: if client did not recieve the acknowledgement, it would start from the beginning</li>
</ul>
</li>
<li><p><strong>Dispatch</strong>:<br> it sends the data block to specific datanode directly (all datanode needless to send data)</p>
<ul>
<li>Bottleneck: speed for writing data into the datanode does not based on the network speed</li>
</ul>
</li>
</ol>
</li>
</ul>
<h2 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h2><p>Yet Another Resource Negotiator (YARN) provides APIs for computing frameworks (e.g., MapReduce) to request and work with cluster resources (<font color="F54747">Goal: decouple programming model and resource management</font>).<br><img src="https://p.ipic.vip/3e4rai.png" width="500px" /></p>
<ul>
<li><strong>Workflow</strong><ol>
<li>The client requests the resource manager for running an application master process</li>
<li>The resource manager finds a node manager to launch the application master in a container</li>
<li>The application master may request more resources if necessary</li>
<li>The application master runs the requests in containers</li>
</ol>
</li>
</ul>
<!-- 
<img src="" width="500px" />
<font color="3A75EA">Blue</font>
<font color="F54747">Red</font>
<font color="880ED4">Purple</font>
<font color="00A300">Green</font>
-->
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="https://github.com/DonaldLamNL/myBlog">Donald Lam</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://github.com/DonaldLamNL/myBlog/2023/09/15/CUHK/CSCI4180/2023-9-15-CSCI4180-Hadoop/">https://github.com/DonaldLamNL/myBlog/2023/09/15/CUHK/CSCI4180/2023-9-15-CSCI4180-Hadoop/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/myBlog/tags/Big-Data-Systems/">Big Data Systems</a><a class="post-meta__tags" href="/myBlog/tags/Cloud-Computing/">Cloud Computing</a></div><div class="post_share"><div class="social-share" data-image="https://p.ipic.vip/hwdr0p.jpg" data-sites="facebook,twitter"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/myBlog/2023/09/18/CUHK/ESTR4300/2023-9-18-ESTR4300-Hadoop-Clusters-Setup/"><img class="prev-cover" src="https://p.ipic.vip/hwdr0p.jpg" onerror="onerror=null;src='/myBlog/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">Hadoop Cluster Setup</div></div></a></div><div class="next-post pull-right"><a href="/myBlog/2023/07/08/Research/dictionary/"><img class="next-cover" src="https://p.ipic.vip/ruvwfy.jpg" onerror="onerror=null;src='/myBlog/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Dictionary</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/myBlog/2023/09/18/CUHK/ESTR4300/2023-9-18-ESTR4300-Hadoop-Clusters-Setup/" title="Hadoop Cluster Setup"><img class="cover" src="https://p.ipic.vip/hwdr0p.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-18</div><div class="title">Hadoop Cluster Setup</div></div></a></div><div><a href="/myBlog/2024/01/18/CUHK/ESTR4316/2024-1-18-ESTR4316-Introduction/" title="Resource Management and Infrastructure"><img class="cover" src="https://p.ipic.vip/hwdr0p.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-18</div><div class="title">Resource Management and Infrastructure</div></div></a></div><div><a href="/myBlog/2024/01/18/CUHK/ESTR4316/2024-1-25-ESTR4316-Kubernates/" title="Hadoop over Kubernetes"><img class="cover" src="https://p.ipic.vip/hwdr0p.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-18</div><div class="title">Hadoop over Kubernetes</div></div></a></div><div><a href="/myBlog/2023/10/15/CUHK/CSCI4180/2023-10-15-CSCI4180-MapReduce/" title="MapReduce Programming"><img class="cover" src="https://p.ipic.vip/ppekay.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-15</div><div class="title">MapReduce Programming</div></div></a></div><div><a href="/myBlog/2023/10/30/CUHK/CSCI4180/2023-10-30-CSCI4180-MapReduce-Applications/" title="MapReduce Applications"><img class="cover" src="https://p.ipic.vip/ppekay.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-30</div><div class="title">MapReduce Applications</div></div></a></div><div><a href="/myBlog/2023/11/25/CUHK/CSCI4180/2023-11-25-CSCI4180-Duplication/" title="Duplication"><img class="cover" src="https://p.ipic.vip/ppekay.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-25</div><div class="title">Duplication</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://p.ipic.vip/5dc8z2.jpeg" onerror="this.onerror=null;this.src='/myBlog/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Donald Lam</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/myBlog/archives/"><div class="headline">Articles</div><div class="length-num">66</div></a><a href="/myBlog/tags/"><div class="headline">Tags</div><div class="length-num">14</div></a><a href="/myBlog/categories/"><div class="headline">Categories</div><div class="length-num">14</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://donaldlamnl.github.io/myWeb/#/home"><i></i><span>My Personal Website</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/DonaldLamNL" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:manholam8@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop"><span class="toc-number">1.</span> <span class="toc-text">Hadoop</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce"><span class="toc-number">1.1.</span> <span class="toc-text">MapReduce</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Programming-Model"><span class="toc-number">1.1.1.</span> <span class="toc-text">Programming Model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Data-Flow"><span class="toc-number">1.1.2.</span> <span class="toc-text">Data Flow</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Partition-and-Combiner"><span class="toc-number">1.1.3.</span> <span class="toc-text">Partition and Combiner</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS"><span class="toc-number">1.2.</span> <span class="toc-text">HDFS</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS-Architectural"><span class="toc-number">1.2.1.</span> <span class="toc-text">HDFS Architectural</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Read"><span class="toc-number">1.2.2.</span> <span class="toc-text">Read</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Write"><span class="toc-number">1.2.3.</span> <span class="toc-text">Write</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#YARN"><span class="toc-number">1.3.</span> <span class="toc-text">YARN</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/myBlog/2024/02/04/CUHK/AIST4010/2024-2-4-AIST4010-Increase-dimension/" title="CNN++ (Increase Dimension)"><img src="https://p.ipic.vip/llqylk.jpg" onerror="this.onerror=null;this.src='/myBlog/img/404.jpg'" alt="CNN++ (Increase Dimension)"/></a><div class="content"><a class="title" href="/myBlog/2024/02/04/CUHK/AIST4010/2024-2-4-AIST4010-Increase-dimension/" title="CNN++ (Increase Dimension)">CNN++ (Increase Dimension)</a><time datetime="2024-02-03T16:00:00.000Z" title="Created 2024-02-04 00:00:00">2024-02-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/myBlog/2024/02/03/CUHK/AIST4010/2024-2-3-AIST4010-Model-Architectures/" title="CNN++ (Model Architectures)"><img src="https://p.ipic.vip/llqylk.jpg" onerror="this.onerror=null;this.src='/myBlog/img/404.jpg'" alt="CNN++ (Model Architectures)"/></a><div class="content"><a class="title" href="/myBlog/2024/02/03/CUHK/AIST4010/2024-2-3-AIST4010-Model-Architectures/" title="CNN++ (Model Architectures)">CNN++ (Model Architectures)</a><time datetime="2024-02-02T16:00:00.000Z" title="Created 2024-02-03 00:00:00">2024-02-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/myBlog/2024/01/30/CUHK/AIST4010/2024-1-30-AIST4010-Convolutional-Neural-Network/" title="Convolutional Neural Network"><img src="https://p.ipic.vip/llqylk.jpg" onerror="this.onerror=null;this.src='/myBlog/img/404.jpg'" alt="Convolutional Neural Network"/></a><div class="content"><a class="title" href="/myBlog/2024/01/30/CUHK/AIST4010/2024-1-30-AIST4010-Convolutional-Neural-Network/" title="Convolutional Neural Network">Convolutional Neural Network</a><time datetime="2024-01-29T16:00:00.000Z" title="Created 2024-01-30 00:00:00">2024-01-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/myBlog/2024/01/29/CUHK/AIST4010/2024-1-29-AIST4010-Overfitting/" title="Overfitting"><img src="https://p.ipic.vip/llqylk.jpg" onerror="this.onerror=null;this.src='/myBlog/img/404.jpg'" alt="Overfitting"/></a><div class="content"><a class="title" href="/myBlog/2024/01/29/CUHK/AIST4010/2024-1-29-AIST4010-Overfitting/" title="Overfitting">Overfitting</a><time datetime="2024-01-28T16:00:00.000Z" title="Created 2024-01-29 00:00:00">2024-01-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/myBlog/2024/01/28/CUHK/AIST4010/2024-1-28-AIST4010-Neural-Network%20copy/" title="Neural Network"><img src="https://p.ipic.vip/llqylk.jpg" onerror="this.onerror=null;this.src='/myBlog/img/404.jpg'" alt="Neural Network"/></a><div class="content"><a class="title" href="/myBlog/2024/01/28/CUHK/AIST4010/2024-1-28-AIST4010-Neural-Network%20copy/" title="Neural Network">Neural Network</a><time datetime="2024-01-27T16:00:00.000Z" title="Created 2024-01-28 00:00:00">2024-01-28</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By Donald Lam</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/myBlog/js/utils.js"></script><script src="/myBlog/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/myBlog/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>